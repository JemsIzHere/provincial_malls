{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdc8d5-d4a4-496d-974e-a73d211aeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# Function to format polygon points as a string in the required format\n",
    "def format_polygon_points(polygon_points):\n",
    "    formatted_points = \", \".join([f\"{lon} {lat}\" for lat, lon in polygon_points])\n",
    "    return f\"POLYGON (({formatted_points}))\"\n",
    "# Function to get polygon points from OpenStreetMap within the Philippines boundary\n",
    "def get_polygon_points(place_name):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "    // Define the boundary for the Philippines\n",
    "    area[name=\"Philippines\"];\n",
    "    // Query for the place name within the Philippines boundary\n",
    "    area[name=\"{place_name}\"](area);\n",
    "    // Output the geometry of the area\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    response = requests.post(overpass_url, data=overpass_query)\n",
    "    data = response.json()\n",
    "    if 'elements' in data and len(data['elements']) > 0:\n",
    "        element = data['elements'][0]\n",
    "        if 'type' in element and element['type'] == 'way':\n",
    "            # Extract polygon points\n",
    "            polygon_points = [(node['lat'], node['lon']) for node in element['geometry']]\n",
    "            return format_polygon_points(polygon_points)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6598211-dc9e-43d8-9b3d-2a0e7cc6338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_shopping_malls_in_the_Philippines\"\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# Find all tables containing shopping mall data except those under construction\n",
    "all_tables = soup.find_all('table', class_='wikitable')\n",
    "filtered_tables = [table for table in all_tables if not table.find_previous('span', class_='mw-headline', text='Shopping malls under construction')]\n",
    "# Major developers list\n",
    "major_developers = [\"Ayala Land\", \"SM Prime Holdings\", \"Robinsons Land\", \"Filinvest Land\", \"Megaworld Corporation\"]\n",
    "# Function to extract data from a given table\n",
    "def extract_data(table):\n",
    "    max_columns = 0\n",
    "    for row in table.find_all('tr'):\n",
    "        columns = row.find_all(['td', 'th'])\n",
    "        max_columns = max(max_columns, len(columns))\n",
    "    malls_data = []\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the first row\n",
    "        columns = row.find_all(['td', 'th'])\n",
    "        if len(columns) == max_columns:\n",
    "            name = re.sub(r'\\[.*?\\]', '', columns[0].text.strip())  # Remove characters within square brackets\n",
    "            city = re.sub(r'\\[.*?\\]', '', columns[1].text.strip())\n",
    "            developer_index = 4 if max_columns == 7 else 3  # Adjust index based on the number of columns\n",
    "            developer = re.sub(r'\\[.*?\\]', '', columns[developer_index].text.strip()) if developer_index < len(columns) else ''\n",
    "            is_major_developer = any(dev in developer for dev in major_developers)  # Check if any major developer is present\n",
    "            malls_data.append((name, city, developer, \"TRUE\" if is_major_developer else \"FALSE\"))\n",
    "        elif len(columns) == max_columns - 1:\n",
    "            name = re.sub(r'\\[.*?\\]', '', columns[0].text.strip())\n",
    "            city = re.sub(r'\\[.*?\\]', '', columns[1].text.strip())\n",
    "            malls_data.append((name, city, \"\", \"FALSE\"))  # Set developer field blank and major developer as FALSE\n",
    "    return malls_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf6fbe-37ee-415c-bfac-8297cf378bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "developers = [\"Ayala Land\", \"SM Prime Holdings\", \"Robinsons Land\", \"Filinvest Land\", \"Megaworld Corporation\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Extract data from filtered tables\n",
    "all_malls_data = {}\n",
    "for table in filtered_tables:\n",
    "    category = table.find_previous('span', class_='mw-headline').text\n",
    "    all_malls_data[category] = extract_data(table)\n",
    "    \n",
    "# List of mall values\n",
    "mall_names = [mall[0] for malls in all_malls_data.values() for mall in malls]\n",
    "mall_loc = [mall[1] for malls in all_malls_data.values() for mall in malls]\n",
    "mall_dev = [mall[2] for malls in all_malls_data.values() for mall in malls]\n",
    "\n",
    "# convert to Data Frame\n",
    "df_mall_loc = pd.DataFrame(mall_loc, columns=['address_city'])\n",
    "df_mall_names = pd.DataFrame(mall_names, columns=['mall_name'])\n",
    "df_mall_dev = pd.DataFrame(mall_dev, columns=['developer_name'])\n",
    "\n",
    "\n",
    "df = pd.concat([df_mall_loc,df_mall_names,df_mall_dev], axis=1)\n",
    "\n",
    "\n",
    "# check if it is major corp\n",
    "df['is_major_corp'] = np.where(df['developer_name'].isin(developers), True, False)\n",
    "\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6c845-5eec-4468-859f-6379ac1bc467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and print polygon strings for each mall within the Philippines boundary\n",
    "polygon_points = []\n",
    "\n",
    "mall_names = df['mall_name']\n",
    "\n",
    "for mall_name in mall_names:\n",
    "    polygon_string = get_polygon_points(mall_name)\n",
    "    if polygon_string:\n",
    "        polygon_points.append(polygon_string)\n",
    "    else:\n",
    "        polygon_points.append(None)\n",
    "\n",
    "df['polygon'] = polygon_points\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f44fa5-ffd3-4dac-9a6c-f260bc537d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c2745-23eb-40bd-b8ac-1fcd8957f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not found use the other method\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "\n",
    "def format_polygon_points(polygon_points):\n",
    "    formatted_points = \", \".join([f\"{lat} {lon}\" for lat, lon in polygon_points])\n",
    "    return f\"POLYGON (({formatted_points}))\"\n",
    "\n",
    "def get_polygon_points(mall_name):\n",
    "    try:\n",
    "        area = ox.geocode_to_gdf(mall_name)\n",
    "        if area.empty:\n",
    "            return []\n",
    "        polygon_points = []\n",
    "        for geometry in area.geometry:\n",
    "            polygon_points.extend(geometry.exterior.coords)\n",
    "        return polygon_points\n",
    "    except (ox.geocoder.InsufficientResponseError, TypeError, AttributeError):\n",
    "        print(f\"Mall Name: {mall_name}  Polygon_points: still not found\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688ad53-eb5d-4af7-8287-fcd1010b7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['polygon']):\n",
    "        mall_name = row['mall_name']\n",
    "        \n",
    "        # Call get_polygon_points with the mall name\n",
    "        polygon_points = get_polygon_points(mall_name)\n",
    "        \n",
    "        if polygon_points:\n",
    "            # Update the 'polygon' column in the DataFrame with the new polygon points\n",
    "            df.at[index, 'polygon'] = format_polygon_points(polygon_points)\n",
    "        else:\n",
    "            df.at[index, 'polygon'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fb380-5617-4d27-a70a-9ba113353e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to normal csv\n",
    "df.to_csv('provincial_malls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addf1d8-ece0-418b-8d5b-cb3f720c5e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
